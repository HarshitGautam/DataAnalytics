{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a list\n",
    "\n",
    "a = ['aa', 'bb', 'cccz', 'd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'bb', 'cccz', 'd']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d', 'aa', 'bb', 'cccz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(a, key = len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = [4, 8,7,9,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 7, 9, 2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 7, 8, 9]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function sorted in module __builtin__:\n",
      "\n",
      "sorted(...)\n",
      "    sorted(iterable, cmp=None, key=None, reverse=False) --> new sorted list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 7, 4, 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(num, reverse= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for customised sorting \n",
    "\n",
    "def lastChar(s):\n",
    "    return(s[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'bb', 'd', 'cccz']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(a, key= lastChar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a= ':'.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa:bb:cccz:d'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = a.split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'bb', 'cccz', 'd']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aabbccczd'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'bb', 'cccz', 'd']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for char in a:\n",
    "    result.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'bb', 'cccz', 'd']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary\n",
    "\n",
    "d={}\n",
    "d['a'] = 'alpha'\n",
    "d['o'] = 'omega'\n",
    "d['g'] = 'gamma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alpha'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2a91c97dbb82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m's'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 's'"
     ]
    }
   ],
   "source": [
    "d['s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'omega'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.get('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d.get('xa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'g' in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'g', 'o']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: a -> alpha\n",
      "key: g -> gamma\n",
      "key: o -> omega\n"
     ]
    }
   ],
   "source": [
    "for k in sorted(d.keys()):\n",
    "    print 'key:',k, '->', d[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'alpha'), ('g', 'gamma'), ('o', 'omega')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'alpha')\n",
      "('g', 'gamma')\n",
      "('o', 'omega')\n"
     ]
    }
   ],
   "source": [
    "for c in d.items():\n",
    "    print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cat(filename):\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        print line\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data Mechanisms (Determine the pattern of your missing data)\n",
      "\n",
      "Here x is your subject on which survey is being done and y is your missing value.\n",
      "\n",
      "-\tMissing Completely at Random (MCAR)\n",
      "\n",
      "Missing value (y) neither depends on x nor y \n",
      "\n",
      "Example: \n",
      "\n",
      "1.\tSome survey questions asked of a simple random sample of original sample\n",
      "\n",
      "2.\t If some quality-of-life questionnaires were lost in the postal system, this would be unlikely to be related to the quality of life of the trial participants who completed the forms.\n",
      "\n",
      "3.\tWe want to assess which are the main determinants of income (such as age). The MCAR assumption would be violated if people who did not report their income were, on average, younger than people who reported it. This can be tested by dividing the sample into those who did and did not report their income, and then testing a difference in mean age. If we fail to reject the null hypothesis, then we can conclude that the MCAR is mostly fulfilled (there could still be some relationship between missingness of Y and the values of Y)\n",
      "\n",
      "\n",
      "\n",
      "-\tMissing at Random (MAR) \n",
      "\n",
      "Missing value (y) depends on x, but not y. A weaker assumption than MCAR\n",
      "\n",
      "Example: \n",
      "\n",
      "1.\tRespondents in service occupations less likely to report income.\n",
      "\n",
      "2.\tThe MAR assumption would be satisfied if the probability of missing data on income depended on a person’s age, but within age group the probability of missing income was unrelated to income. However, this cannot be tested because we do not know the values of the missing data, thus, we cannot compare the values of those with and without missing data to see if they systematically differ on that variable.\n",
      "\n",
      "\n",
      "\n",
      "-\tMissing not at Random (NMAR) \n",
      "\n",
      "The probability of a missing value depends on the variable that is missing. Missing not at random is your worst-case scenario. Proceed with caution.\n",
      "\n",
      "Example:\n",
      "\n",
      "1.\tRespondents with high income less likely to report income\n",
      "\n",
      "2.\tIn a depression trial, participants who had a relapse of depression might be less likely to attend the final follow-up interview, and more likely to have missing outcome data. \n",
      "\n",
      "\n",
      "\n",
      "Keep in mind when you proceed from here -\n",
      "\n",
      "If MAR assumption is fulfilled: The missing data mechanism is said to be ignorable, which basically means that there is no need to model the missing data mechanism as part of the estimation process. These are the method this report will cover.\n",
      "\n",
      "If MAR assumption is not fulfilled: The missing data mechanism is said to be nonignorable and, thus, it must be modeled to get good estimates of the parameters of interest. This requires a very good understanding of the missing data process\n",
      "\n",
      "\n",
      "\n",
      "Few ways to handle the missing data.\n",
      "\n",
      "\tListwise Deletion: Delete all data from any participant with missing values. If your sample is large enough, then you likely can drop data without substantial loss of statistical power. Be sure that the values are missing at random and that you are not inadvertently removing a class of participants.\n",
      "\n",
      "Advantages: It can be used with any kind of statistical analysis and no special computational methods are required. \n",
      "\n",
      "Limitations: It can exclude a large fraction of the original sample. For example, suppose a data set with 1,000 people and 20 variables. Each of the variables has missing data on 5% of the cases, then, you could expect to have complete data for only about 360 individuals, discarding the other 640. It works well when the data are missing completely at random (MCAR), which rarely happens in reality.\n",
      "\n",
      "\n",
      "\n",
      "\tRecover the Values: You can sometimes contact the participants and ask them to fill out the missing values. For in-person studies, we've found having an additional check for missing values before the participant leaves helps.\n",
      "\n",
      "\n",
      "\n",
      "Imputation\n",
      "\n",
      "In statistics, imputation is the process of replacing missing data with substituted values. When substituting for a data point, it is known as \"unit imputation\"; when substituting for a component of a data point, it is known as \"item imputation\". The following methods use some form of imputation.\n",
      "\n",
      "\tEducated Guessing: It sounds arbitrary and isn't your preferred course of action, but you can often infer a missing value. For related questions, for example, like those often presented in a matrix, if the participant responds with all \"4s\", assume that the missing value is a 4.\n",
      "\n",
      "\n",
      "\n",
      "\tMarginal mean or median imputation: Compute the mean of X using the non-missing values and use it to impute missing values of X. Limitations: It leads to biased estimates of variances and covariances and, generally, it should be avoided. \n",
      "\n",
      "If there is a dataset that have great outliers, I'll prefer median. E.x.: 99% of household income is below 100, and 1% is above 500.\n",
      "\n",
      "On the other hand, if we work with wear of clothes that customers give to dry-cleaner (assuming that dry-cleaners' operators fill this field intuitively), I'll fill missings with mean value of wear.\n",
      "\n",
      "\tConditional mean imputation: Suppose we are estimating a regression model with multiple independent variables. One of them, X, has missing values. We select those cases with complete information and regress X on all the other independent variables. Then, we use the estimated equation to predict X for those cases it is missing. If the data are MCAR, least-squares coefficients are consistent (i.e. unbiased as the sample size increases) but they are not fully efficient (remember, efficiency is a measure of the optimality of an estimator. Essentially, a more efficient estimator, experiment or test needs fewer samples than a less efficient one to achieve a given performance). Estimating the model using weighted least squares or generalized least squares leads to better results (Graham, 2009) (Allison, 2001) and (Briggs et al., 2003).\n",
      "\n",
      "\n",
      "\n",
      "\tCommon-Point Imputation: For a rating scale, using the middle point or most commonly chosen value. For example, on a five-point scale, substitute a 3, the midpoint, or a 4, the most common value (in many cases). This is a bit more structured than guessing, but it's still among the more risky options. Use caution unless you have good reason and data to support using the substitute value.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tMultiple Imputation: The imputed values are draws from a distribution, so they inherently contain some variation. Thus, multiple imputation (MI) solves the limitations of single imputation by introducing an additional form of error based on variation in the parameter estimates across the imputation, which is called “between imputation error”. It replaces each missing item with two or more acceptable values, representing a distribution of possibilities (Allison, 2001).\n",
      "\n",
      "MI is a simulation-based procedure. Its purpose is not to re-create the individual missing values as close as possible to the true ones, but to handle missing data to achieve valid statistical inference (Schafer, 1997).\n",
      "\n",
      "\n",
      "\n",
      "It involves 3 steps: \n",
      "\n",
      "a) Running an imputation model defined by the chosen variables to create imputed data sets. In other words, the missing values are filled in m times to generate m complete data sets. m=20 is considered good enough. Correct model choices require considering:\n",
      "\n",
      "Firstly, we should identify which are the variables with missing values.\n",
      "\n",
      "Secondly, we should compute the proportion of missing values for each variable.\n",
      "\n",
      "Thirdly, we should assess whether different missing value patterns exist in the data (SAS helps us doing this), and try to understand the nature of the missing values. Some key questions are:\n",
      "\n",
      "Are there a lot of missing values for certain variables? (E.g. Sensitive question, data entry errors?)\n",
      "\n",
      "Are there groups of subjects with very little information available? (E.g. Do they have something in common?)\n",
      "\n",
      "Which is the pattern of missingness? Monotone or arbitrary? \n",
      "\n",
      "b) The m complete data sets are analyzed by using standard procedures \n",
      "\n",
      "c) The parameter estimates from each imputed data set are combined to get a final set of parameter estimates.\n",
      "\n",
      "Advantages: It has the same optimal properties as ML, and it removes some of its limitations. Multiple imputation can be used with any kind of data and model with conventional software. When the data is MAR, multiple imputation can lead to consistent, asymptotically efficient, and asymptotically normal estimates. \n",
      "\n",
      "Limitations: It is a bit challenging to successfully use it. It produces different estimates (hopefully, only slightly different) every time you use it, which can lead to situations where different researchers get different numbers from the same data using the same method (Nakai & Weiming, 2011), (Allison, 2001).\n",
      "\n",
      "\n",
      "\n",
      "\tMaximum Likelihood: We can use this method to get the variance-covariance matrix for the variables in the model based on all the available data points, and then use the obtained variance- covariance matrix to estimate our regression model (Schafer, 1997). \n",
      "\n",
      "Compared to MI, MI requires many more decisions than ML (whether to use Markov Chain Monte Carlo (MCMC) method or the Fully Conditional Specification (FCS), how many data sets to produce, how many iterations between data sets, what prior distribution to use-the default is Jeffreys-, etc.). On the other hand, ML is simpler as you only need to specify your model of interest and indicate that you want to use ML ( SAS Institute, 2005).\n",
      "\n",
      "There are two main ML methods: \n",
      "\n",
      "a) Direct Maximum Likelihood: It implies the direct maximization of the multivariate normal likelihood function for the assumed linear model. Advantage: It gives efficient estimates with correct standard errors. Limitations: It requires specialized software (it may be challenging and time consuming).\n",
      "\n",
      " b) The Expectation-maximization (EM) algorithm: It provides estimates of the means and covariance matrix, which can be used to get consistent estimates of the parameters of interest. It is based on an expectation step and a maximization step, which are repeated several times until maximum likelihood estimates are obtained. It requires a large sample size and that the data are missing at random (MAR). Advantage: We can use SAS, since this is the default algorithm it employs for dealing with missing data with Maximum Likelihood. Limitations: Only can be used for linear and log-linear models (there is neither theory nor software developed beyond them). (Allison, 2001) (Graham, 2009) (Enders & Bandalos, 2001) and (Allison, 2003)\n",
      "\n",
      "\n",
      "\n",
      "Sources and References:\n",
      "\n",
      "•\thttp://handbook.cochrane.org/chapter_16/16_1_2_general_principles_for_dealing_with_missing_data.htm\n",
      "\n",
      "•\thttps://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf\n",
      "\n",
      "•\thttp://www.measuringu.com/blog/handle-missing-data.php\n",
      "\n",
      "•\thttp://www.bu.edu/sph/files/2014/05/Marina-tech-report.pdf\n",
      "\n",
      "•\thttp://galton.uchicago.edu/~eichler/stat24600/Admin/MissingDataReview.pdf\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Cat('C:/Users/hgsgautam/Desktop/Python/TestText.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Cat_1(filename):\n",
    "    f = open(filename, 'r')\n",
    "    lines = f.readlines()\n",
    "    print lines,\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Missing Data Mechanisms (Determine the pattern of your missing data)\\n', 'Here x is your subject on which survey is being done and y is your missing value.\\n', '-\\tMissing Completely at Random (MCAR)\\n', 'Missing value (y) neither depends on x nor y \\n', 'Example: \\n', '1.\\tSome survey questions asked of a simple random sample of original sample\\n', '2.\\t If some quality-of-life questionnaires were lost in the postal system, this would be unlikely to be related to the quality of life of the trial participants who completed the forms.\\n', '3.\\tWe want to assess which are the main determinants of income (such as age). The MCAR assumption would be violated if people who did not report their income were, on average, younger than people who reported it. This can be tested by dividing the sample into those who did and did not report their income, and then testing a difference in mean age. If we fail to reject the null hypothesis, then we can conclude that the MCAR is mostly fulfilled (there could still be some relationship between missingness of Y and the values of Y)\\n', '\\n', '-\\tMissing at Random (MAR) \\n', 'Missing value (y) depends on x, but not y. A weaker assumption than MCAR\\n', 'Example: \\n', '1.\\tRespondents in service occupations less likely to report income.\\n', '2.\\tThe MAR assumption would be satisfied if the probability of missing data on income depended on a person\\xe2\\x80\\x99s age, but within age group the probability of missing income was unrelated to income. However, this cannot be tested because we do not know the values of the missing data, thus, we cannot compare the values of those with and without missing data to see if they systematically differ on that variable.\\n', '\\n', '-\\tMissing not at Random (NMAR) \\n', 'The probability of a missing value depends on the variable that is missing. Missing not at random is your worst-case scenario. Proceed with caution.\\n', 'Example:\\n', '1.\\tRespondents with high income less likely to report income\\n', '2.\\tIn a depression trial, participants who had a relapse of depression might be less likely to attend the final follow-up interview, and more likely to have missing outcome data. \\n', '\\n', 'Keep in mind when you proceed from here -\\n', 'If MAR assumption is fulfilled: The missing data mechanism is said to be ignorable, which basically means that there is no need to model the missing data mechanism as part of the estimation process. These are the method this report will cover.\\n', 'If MAR assumption is not fulfilled: The missing data mechanism is said to be nonignorable and, thus, it must be modeled to get good estimates of the parameters of interest. This requires a very good understanding of the missing data process\\n', '\\n', 'Few ways to handle the missing data.\\n', '\\xef\\x83\\x98\\tListwise Deletion: Delete all data from any participant with missing values. If your sample is large enough, then you likely can drop data without substantial loss of statistical power. Be sure that the values are missing at random and that you are not inadvertently removing a class of participants.\\n', 'Advantages: It can be used with any kind of statistical analysis and no special computational methods are required. \\n', 'Limitations: It can exclude a large fraction of the original sample. For example, suppose a data set with 1,000 people and 20 variables. Each of the variables has missing data on 5% of the cases, then, you could expect to have complete data for only about 360 individuals, discarding the other 640. It works well when the data are missing completely at random (MCAR), which rarely happens in reality.\\n', '\\n', \"\\xef\\x83\\x98\\tRecover the Values: You can sometimes contact the participants and ask them to fill out the missing values. For in-person studies, we've found having an additional check for missing values before the participant leaves helps.\\n\", '\\n', 'Imputation\\n', 'In statistics, imputation is the process of replacing missing data with substituted values. When substituting for a data point, it is known as \"unit imputation\"; when substituting for a component of a data point, it is known as \"item imputation\". The following methods use some form of imputation.\\n', '\\xef\\x83\\x98\\tEducated Guessing: It sounds arbitrary and isn\\'t your preferred course of action, but you can often infer a missing value. For related questions, for example, like those often presented in a matrix, if the participant responds with all \"4s\", assume that the missing value is a 4.\\n', '\\n', '\\xef\\x83\\x98\\tMarginal mean or median imputation: Compute the mean of X using the non-missing values and use it to impute missing values of X. Limitations: It leads to biased estimates of variances and covariances and, generally, it should be avoided. \\n', \"If there is a dataset that have great outliers, I'll prefer median. E.x.: 99% of household income is below 100, and 1% is above 500.\\n\", \"On the other hand, if we work with wear of clothes that customers give to dry-cleaner (assuming that dry-cleaners' operators fill this field intuitively), I'll fill missings with mean value of wear.\\n\", '\\xef\\x83\\x98\\tConditional mean imputation: Suppose we are estimating a regression model with multiple independent variables. One of them, X, has missing values. We select those cases with complete information and regress X on all the other independent variables. Then, we use the estimated equation to predict X for those cases it is missing. If the data are MCAR, least-squares coefficients are consistent (i.e. unbiased as the sample size increases) but they are not fully efficient (remember, efficiency is a measure of the optimality of an estimator. Essentially, a more efficient estimator, experiment or test needs fewer samples than a less efficient one to achieve a given performance). Estimating the model using weighted least squares or generalized least squares leads to better results (Graham, 2009) (Allison, 2001) and (Briggs et al., 2003).\\n', '\\n', \"\\xef\\x83\\x98\\tCommon-Point Imputation: For a rating scale, using the middle point or most commonly chosen value. For example, on a five-point scale, substitute a 3, the midpoint, or a 4, the most common value (in many cases). This is a bit more structured than guessing, but it's still among the more risky options. Use caution unless you have good reason and data to support using the substitute value.\\n\", '\\n', '\\n', '\\xef\\x83\\x98\\tMultiple Imputation: The imputed values are draws from a distribution, so they inherently contain some variation. Thus, multiple imputation (MI) solves the limitations of single imputation by introducing an additional form of error based on variation in the parameter estimates across the imputation, which is called \\xe2\\x80\\x9cbetween imputation error\\xe2\\x80\\x9d. It replaces each missing item with two or more acceptable values, representing a distribution of possibilities (Allison, 2001).\\n', 'MI is a simulation-based procedure. Its purpose is not to re-create the individual missing values as close as possible to the true ones, but to handle missing data to achieve valid statistical inference (Schafer, 1997).\\n', '\\n', 'It involves 3 steps: \\n', 'a) Running an imputation model defined by the chosen variables to create imputed data sets. In other words, the missing values are filled in m times to generate m complete data sets. m=20 is considered good enough. Correct model choices require considering:\\n', 'Firstly, we should identify which are the variables with missing values.\\n', 'Secondly, we should compute the proportion of missing values for each variable.\\n', 'Thirdly, we should assess whether different missing value patterns exist in the data (SAS helps us doing this), and try to understand the nature of the missing values. Some key questions are:\\n', 'Are there a lot of missing values for certain variables? (E.g. Sensitive question, data entry errors?)\\n', 'Are there groups of subjects with very little information available? (E.g. Do they have something in common?)\\n', 'Which is the pattern of missingness? Monotone or arbitrary? \\n', 'b) The m complete data sets are analyzed by using standard procedures \\n', 'c) The parameter estimates from each imputed data set are combined to get a final set of parameter estimates.\\n', 'Advantages: It has the same optimal properties as ML, and it removes some of its limitations. Multiple imputation can be used with any kind of data and model with conventional software. When the data is MAR, multiple imputation can lead to consistent, asymptotically efficient, and asymptotically normal estimates. \\n', 'Limitations: It is a bit challenging to successfully use it. It produces different estimates (hopefully, only slightly different) every time you use it, which can lead to situations where different researchers get different numbers from the same data using the same method (Nakai & Weiming, 2011), (Allison, 2001).\\n', '\\n', '\\xef\\x83\\x98\\tMaximum Likelihood: We can use this method to get the variance-covariance matrix for the variables in the model based on all the available data points, and then use the obtained variance- covariance matrix to estimate our regression model (Schafer, 1997). \\n', 'Compared to MI, MI requires many more decisions than ML (whether to use Markov Chain Monte Carlo (MCMC) method or the Fully Conditional Specification (FCS), how many data sets to produce, how many iterations between data sets, what prior distribution to use-the default is Jeffreys-, etc.). On the other hand, ML is simpler as you only need to specify your model of interest and indicate that you want to use ML ( SAS Institute, 2005).\\n', 'There are two main ML methods: \\n', 'a) Direct Maximum Likelihood: It implies the direct maximization of the multivariate normal likelihood function for the assumed linear model. Advantage: It gives efficient estimates with correct standard errors. Limitations: It requires specialized software (it may be challenging and time consuming).\\n', ' b) The Expectation-maximization (EM) algorithm: It provides estimates of the means and covariance matrix, which can be used to get consistent estimates of the parameters of interest. It is based on an expectation step and a maximization step, which are repeated several times until maximum likelihood estimates are obtained. It requires a large sample size and that the data are missing at random (MAR). Advantage: We can use SAS, since this is the default algorithm it employs for dealing with missing data with Maximum Likelihood. Limitations: Only can be used for linear and log-linear models (there is neither theory nor software developed beyond them). (Allison, 2001) (Graham, 2009) (Enders & Bandalos, 2001) and (Allison, 2003)\\n', '\\n', 'Sources and References:\\n', '\\xe2\\x80\\xa2\\thttp://handbook.cochrane.org/chapter_16/16_1_2_general_principles_for_dealing_with_missing_data.htm\\n', '\\xe2\\x80\\xa2\\thttps://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf\\n', '\\xe2\\x80\\xa2\\thttp://www.measuringu.com/blog/handle-missing-data.php\\n', '\\xe2\\x80\\xa2\\thttp://www.bu.edu/sph/files/2014/05/Marina-tech-report.pdf\\n', '\\xe2\\x80\\xa2\\thttp://galton.uchicago.edu/~eichler/stat24600/Admin/MissingDataReview.pdf\\n', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "Cat_1('C:/Users/hgsgautam/Desktop/Python/TestText.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Cat_2(filename):\n",
    "    f = open(filename, 'r')\n",
    "    text = f.read()\n",
    "    d1 = text.split()\n",
    "    print d1,\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Missing', 'Data', 'Mechanisms', '(Determine', 'the', 'pattern', 'of', 'your', 'missing', 'data)', 'Here', 'x', 'is', 'your', 'subject', 'on', 'which', 'survey', 'is', 'being', 'done', 'and', 'y', 'is', 'your', 'missing', 'value.', '-', 'Missing', 'Completely', 'at', 'Random', '(MCAR)', 'Missing', 'value', '(y)', 'neither', 'depends', 'on', 'x', 'nor', 'y', 'Example:', '1.', 'Some', 'survey', 'questions', 'asked', 'of', 'a', 'simple', 'random', 'sample', 'of', 'original', 'sample', '2.', 'If', 'some', 'quality-of-life', 'questionnaires', 'were', 'lost', 'in', 'the', 'postal', 'system,', 'this', 'would', 'be', 'unlikely', 'to', 'be', 'related', 'to', 'the', 'quality', 'of', 'life', 'of', 'the', 'trial', 'participants', 'who', 'completed', 'the', 'forms.', '3.', 'We', 'want', 'to', 'assess', 'which', 'are', 'the', 'main', 'determinants', 'of', 'income', '(such', 'as', 'age).', 'The', 'MCAR', 'assumption', 'would', 'be', 'violated', 'if', 'people', 'who', 'did', 'not', 'report', 'their', 'income', 'were,', 'on', 'average,', 'younger', 'than', 'people', 'who', 'reported', 'it.', 'This', 'can', 'be', 'tested', 'by', 'dividing', 'the', 'sample', 'into', 'those', 'who', 'did', 'and', 'did', 'not', 'report', 'their', 'income,', 'and', 'then', 'testing', 'a', 'difference', 'in', 'mean', 'age.', 'If', 'we', 'fail', 'to', 'reject', 'the', 'null', 'hypothesis,', 'then', 'we', 'can', 'conclude', 'that', 'the', 'MCAR', 'is', 'mostly', 'fulfilled', '(there', 'could', 'still', 'be', 'some', 'relationship', 'between', 'missingness', 'of', 'Y', 'and', 'the', 'values', 'of', 'Y)', '-', 'Missing', 'at', 'Random', '(MAR)', 'Missing', 'value', '(y)', 'depends', 'on', 'x,', 'but', 'not', 'y.', 'A', 'weaker', 'assumption', 'than', 'MCAR', 'Example:', '1.', 'Respondents', 'in', 'service', 'occupations', 'less', 'likely', 'to', 'report', 'income.', '2.', 'The', 'MAR', 'assumption', 'would', 'be', 'satisfied', 'if', 'the', 'probability', 'of', 'missing', 'data', 'on', 'income', 'depended', 'on', 'a', 'person\\xe2\\x80\\x99s', 'age,', 'but', 'within', 'age', 'group', 'the', 'probability', 'of', 'missing', 'income', 'was', 'unrelated', 'to', 'income.', 'However,', 'this', 'cannot', 'be', 'tested', 'because', 'we', 'do', 'not', 'know', 'the', 'values', 'of', 'the', 'missing', 'data,', 'thus,', 'we', 'cannot', 'compare', 'the', 'values', 'of', 'those', 'with', 'and', 'without', 'missing', 'data', 'to', 'see', 'if', 'they', 'systematically', 'differ', 'on', 'that', 'variable.', '-', 'Missing', 'not', 'at', 'Random', '(NMAR)', 'The', 'probability', 'of', 'a', 'missing', 'value', 'depends', 'on', 'the', 'variable', 'that', 'is', 'missing.', 'Missing', 'not', 'at', 'random', 'is', 'your', 'worst-case', 'scenario.', 'Proceed', 'with', 'caution.', 'Example:', '1.', 'Respondents', 'with', 'high', 'income', 'less', 'likely', 'to', 'report', 'income', '2.', 'In', 'a', 'depression', 'trial,', 'participants', 'who', 'had', 'a', 'relapse', 'of', 'depression', 'might', 'be', 'less', 'likely', 'to', 'attend', 'the', 'final', 'follow-up', 'interview,', 'and', 'more', 'likely', 'to', 'have', 'missing', 'outcome', 'data.', 'Keep', 'in', 'mind', 'when', 'you', 'proceed', 'from', 'here', '-', 'If', 'MAR', 'assumption', 'is', 'fulfilled:', 'The', 'missing', 'data', 'mechanism', 'is', 'said', 'to', 'be', 'ignorable,', 'which', 'basically', 'means', 'that', 'there', 'is', 'no', 'need', 'to', 'model', 'the', 'missing', 'data', 'mechanism', 'as', 'part', 'of', 'the', 'estimation', 'process.', 'These', 'are', 'the', 'method', 'this', 'report', 'will', 'cover.', 'If', 'MAR', 'assumption', 'is', 'not', 'fulfilled:', 'The', 'missing', 'data', 'mechanism', 'is', 'said', 'to', 'be', 'nonignorable', 'and,', 'thus,', 'it', 'must', 'be', 'modeled', 'to', 'get', 'good', 'estimates', 'of', 'the', 'parameters', 'of', 'interest.', 'This', 'requires', 'a', 'very', 'good', 'understanding', 'of', 'the', 'missing', 'data', 'process', 'Few', 'ways', 'to', 'handle', 'the', 'missing', 'data.', '\\xef\\x83\\x98', 'Listwise', 'Deletion:', 'Delete', 'all', 'data', 'from', 'any', 'participant', 'with', 'missing', 'values.', 'If', 'your', 'sample', 'is', 'large', 'enough,', 'then', 'you', 'likely', 'can', 'drop', 'data', 'without', 'substantial', 'loss', 'of', 'statistical', 'power.', 'Be', 'sure', 'that', 'the', 'values', 'are', 'missing', 'at', 'random', 'and', 'that', 'you', 'are', 'not', 'inadvertently', 'removing', 'a', 'class', 'of', 'participants.', 'Advantages:', 'It', 'can', 'be', 'used', 'with', 'any', 'kind', 'of', 'statistical', 'analysis', 'and', 'no', 'special', 'computational', 'methods', 'are', 'required.', 'Limitations:', 'It', 'can', 'exclude', 'a', 'large', 'fraction', 'of', 'the', 'original', 'sample.', 'For', 'example,', 'suppose', 'a', 'data', 'set', 'with', '1,000', 'people', 'and', '20', 'variables.', 'Each', 'of', 'the', 'variables', 'has', 'missing', 'data', 'on', '5%', 'of', 'the', 'cases,', 'then,', 'you', 'could', 'expect', 'to', 'have', 'complete', 'data', 'for', 'only', 'about', '360', 'individuals,', 'discarding', 'the', 'other', '640.', 'It', 'works', 'well', 'when', 'the', 'data', 'are', 'missing', 'completely', 'at', 'random', '(MCAR),', 'which', 'rarely', 'happens', 'in', 'reality.', '\\xef\\x83\\x98', 'Recover', 'the', 'Values:', 'You', 'can', 'sometimes', 'contact', 'the', 'participants', 'and', 'ask', 'them', 'to', 'fill', 'out', 'the', 'missing', 'values.', 'For', 'in-person', 'studies,', \"we've\", 'found', 'having', 'an', 'additional', 'check', 'for', 'missing', 'values', 'before', 'the', 'participant', 'leaves', 'helps.', 'Imputation', 'In', 'statistics,', 'imputation', 'is', 'the', 'process', 'of', 'replacing', 'missing', 'data', 'with', 'substituted', 'values.', 'When', 'substituting', 'for', 'a', 'data', 'point,', 'it', 'is', 'known', 'as', '\"unit', 'imputation\";', 'when', 'substituting', 'for', 'a', 'component', 'of', 'a', 'data', 'point,', 'it', 'is', 'known', 'as', '\"item', 'imputation\".', 'The', 'following', 'methods', 'use', 'some', 'form', 'of', 'imputation.', '\\xef\\x83\\x98', 'Educated', 'Guessing:', 'It', 'sounds', 'arbitrary', 'and', \"isn't\", 'your', 'preferred', 'course', 'of', 'action,', 'but', 'you', 'can', 'often', 'infer', 'a', 'missing', 'value.', 'For', 'related', 'questions,', 'for', 'example,', 'like', 'those', 'often', 'presented', 'in', 'a', 'matrix,', 'if', 'the', 'participant', 'responds', 'with', 'all', '\"4s\",', 'assume', 'that', 'the', 'missing', 'value', 'is', 'a', '4.', '\\xef\\x83\\x98', 'Marginal', 'mean', 'or', 'median', 'imputation:', 'Compute', 'the', 'mean', 'of', 'X', 'using', 'the', 'non-missing', 'values', 'and', 'use', 'it', 'to', 'impute', 'missing', 'values', 'of', 'X.', 'Limitations:', 'It', 'leads', 'to', 'biased', 'estimates', 'of', 'variances', 'and', 'covariances', 'and,', 'generally,', 'it', 'should', 'be', 'avoided.', 'If', 'there', 'is', 'a', 'dataset', 'that', 'have', 'great', 'outliers,', \"I'll\", 'prefer', 'median.', 'E.x.:', '99%', 'of', 'household', 'income', 'is', 'below', '100,', 'and', '1%', 'is', 'above', '500.', 'On', 'the', 'other', 'hand,', 'if', 'we', 'work', 'with', 'wear', 'of', 'clothes', 'that', 'customers', 'give', 'to', 'dry-cleaner', '(assuming', 'that', \"dry-cleaners'\", 'operators', 'fill', 'this', 'field', 'intuitively),', \"I'll\", 'fill', 'missings', 'with', 'mean', 'value', 'of', 'wear.', '\\xef\\x83\\x98', 'Conditional', 'mean', 'imputation:', 'Suppose', 'we', 'are', 'estimating', 'a', 'regression', 'model', 'with', 'multiple', 'independent', 'variables.', 'One', 'of', 'them,', 'X,', 'has', 'missing', 'values.', 'We', 'select', 'those', 'cases', 'with', 'complete', 'information', 'and', 'regress', 'X', 'on', 'all', 'the', 'other', 'independent', 'variables.', 'Then,', 'we', 'use', 'the', 'estimated', 'equation', 'to', 'predict', 'X', 'for', 'those', 'cases', 'it', 'is', 'missing.', 'If', 'the', 'data', 'are', 'MCAR,', 'least-squares', 'coefficients', 'are', 'consistent', '(i.e.', 'unbiased', 'as', 'the', 'sample', 'size', 'increases)', 'but', 'they', 'are', 'not', 'fully', 'efficient', '(remember,', 'efficiency', 'is', 'a', 'measure', 'of', 'the', 'optimality', 'of', 'an', 'estimator.', 'Essentially,', 'a', 'more', 'efficient', 'estimator,', 'experiment', 'or', 'test', 'needs', 'fewer', 'samples', 'than', 'a', 'less', 'efficient', 'one', 'to', 'achieve', 'a', 'given', 'performance).', 'Estimating', 'the', 'model', 'using', 'weighted', 'least', 'squares', 'or', 'generalized', 'least', 'squares', 'leads', 'to', 'better', 'results', '(Graham,', '2009)', '(Allison,', '2001)', 'and', '(Briggs', 'et', 'al.,', '2003).', '\\xef\\x83\\x98', 'Common-Point', 'Imputation:', 'For', 'a', 'rating', 'scale,', 'using', 'the', 'middle', 'point', 'or', 'most', 'commonly', 'chosen', 'value.', 'For', 'example,', 'on', 'a', 'five-point', 'scale,', 'substitute', 'a', '3,', 'the', 'midpoint,', 'or', 'a', '4,', 'the', 'most', 'common', 'value', '(in', 'many', 'cases).', 'This', 'is', 'a', 'bit', 'more', 'structured', 'than', 'guessing,', 'but', \"it's\", 'still', 'among', 'the', 'more', 'risky', 'options.', 'Use', 'caution', 'unless', 'you', 'have', 'good', 'reason', 'and', 'data', 'to', 'support', 'using', 'the', 'substitute', 'value.', '\\xef\\x83\\x98', 'Multiple', 'Imputation:', 'The', 'imputed', 'values', 'are', 'draws', 'from', 'a', 'distribution,', 'so', 'they', 'inherently', 'contain', 'some', 'variation.', 'Thus,', 'multiple', 'imputation', '(MI)', 'solves', 'the', 'limitations', 'of', 'single', 'imputation', 'by', 'introducing', 'an', 'additional', 'form', 'of', 'error', 'based', 'on', 'variation', 'in', 'the', 'parameter', 'estimates', 'across', 'the', 'imputation,', 'which', 'is', 'called', '\\xe2\\x80\\x9cbetween', 'imputation', 'error\\xe2\\x80\\x9d.', 'It', 'replaces', 'each', 'missing', 'item', 'with', 'two', 'or', 'more', 'acceptable', 'values,', 'representing', 'a', 'distribution', 'of', 'possibilities', '(Allison,', '2001).', 'MI', 'is', 'a', 'simulation-based', 'procedure.', 'Its', 'purpose', 'is', 'not', 'to', 're-create', 'the', 'individual', 'missing', 'values', 'as', 'close', 'as', 'possible', 'to', 'the', 'true', 'ones,', 'but', 'to', 'handle', 'missing', 'data', 'to', 'achieve', 'valid', 'statistical', 'inference', '(Schafer,', '1997).', 'It', 'involves', '3', 'steps:', 'a)', 'Running', 'an', 'imputation', 'model', 'defined', 'by', 'the', 'chosen', 'variables', 'to', 'create', 'imputed', 'data', 'sets.', 'In', 'other', 'words,', 'the', 'missing', 'values', 'are', 'filled', 'in', 'm', 'times', 'to', 'generate', 'm', 'complete', 'data', 'sets.', 'm=20', 'is', 'considered', 'good', 'enough.', 'Correct', 'model', 'choices', 'require', 'considering:', 'Firstly,', 'we', 'should', 'identify', 'which', 'are', 'the', 'variables', 'with', 'missing', 'values.', 'Secondly,', 'we', 'should', 'compute', 'the', 'proportion', 'of', 'missing', 'values', 'for', 'each', 'variable.', 'Thirdly,', 'we', 'should', 'assess', 'whether', 'different', 'missing', 'value', 'patterns', 'exist', 'in', 'the', 'data', '(SAS', 'helps', 'us', 'doing', 'this),', 'and', 'try', 'to', 'understand', 'the', 'nature', 'of', 'the', 'missing', 'values.', 'Some', 'key', 'questions', 'are:', 'Are', 'there', 'a', 'lot', 'of', 'missing', 'values', 'for', 'certain', 'variables?', '(E.g.', 'Sensitive', 'question,', 'data', 'entry', 'errors?)', 'Are', 'there', 'groups', 'of', 'subjects', 'with', 'very', 'little', 'information', 'available?', '(E.g.', 'Do', 'they', 'have', 'something', 'in', 'common?)', 'Which', 'is', 'the', 'pattern', 'of', 'missingness?', 'Monotone', 'or', 'arbitrary?', 'b)', 'The', 'm', 'complete', 'data', 'sets', 'are', 'analyzed', 'by', 'using', 'standard', 'procedures', 'c)', 'The', 'parameter', 'estimates', 'from', 'each', 'imputed', 'data', 'set', 'are', 'combined', 'to', 'get', 'a', 'final', 'set', 'of', 'parameter', 'estimates.', 'Advantages:', 'It', 'has', 'the', 'same', 'optimal', 'properties', 'as', 'ML,', 'and', 'it', 'removes', 'some', 'of', 'its', 'limitations.', 'Multiple', 'imputation', 'can', 'be', 'used', 'with', 'any', 'kind', 'of', 'data', 'and', 'model', 'with', 'conventional', 'software.', 'When', 'the', 'data', 'is', 'MAR,', 'multiple', 'imputation', 'can', 'lead', 'to', 'consistent,', 'asymptotically', 'efficient,', 'and', 'asymptotically', 'normal', 'estimates.', 'Limitations:', 'It', 'is', 'a', 'bit', 'challenging', 'to', 'successfully', 'use', 'it.', 'It', 'produces', 'different', 'estimates', '(hopefully,', 'only', 'slightly', 'different)', 'every', 'time', 'you', 'use', 'it,', 'which', 'can', 'lead', 'to', 'situations', 'where', 'different', 'researchers', 'get', 'different', 'numbers', 'from', 'the', 'same', 'data', 'using', 'the', 'same', 'method', '(Nakai', '&', 'Weiming,', '2011),', '(Allison,', '2001).', '\\xef\\x83\\x98', 'Maximum', 'Likelihood:', 'We', 'can', 'use', 'this', 'method', 'to', 'get', 'the', 'variance-covariance', 'matrix', 'for', 'the', 'variables', 'in', 'the', 'model', 'based', 'on', 'all', 'the', 'available', 'data', 'points,', 'and', 'then', 'use', 'the', 'obtained', 'variance-', 'covariance', 'matrix', 'to', 'estimate', 'our', 'regression', 'model', '(Schafer,', '1997).', 'Compared', 'to', 'MI,', 'MI', 'requires', 'many', 'more', 'decisions', 'than', 'ML', '(whether', 'to', 'use', 'Markov', 'Chain', 'Monte', 'Carlo', '(MCMC)', 'method', 'or', 'the', 'Fully', 'Conditional', 'Specification', '(FCS),', 'how', 'many', 'data', 'sets', 'to', 'produce,', 'how', 'many', 'iterations', 'between', 'data', 'sets,', 'what', 'prior', 'distribution', 'to', 'use-the', 'default', 'is', 'Jeffreys-,', 'etc.).', 'On', 'the', 'other', 'hand,', 'ML', 'is', 'simpler', 'as', 'you', 'only', 'need', 'to', 'specify', 'your', 'model', 'of', 'interest', 'and', 'indicate', 'that', 'you', 'want', 'to', 'use', 'ML', '(', 'SAS', 'Institute,', '2005).', 'There', 'are', 'two', 'main', 'ML', 'methods:', 'a)', 'Direct', 'Maximum', 'Likelihood:', 'It', 'implies', 'the', 'direct', 'maximization', 'of', 'the', 'multivariate', 'normal', 'likelihood', 'function', 'for', 'the', 'assumed', 'linear', 'model.', 'Advantage:', 'It', 'gives', 'efficient', 'estimates', 'with', 'correct', 'standard', 'errors.', 'Limitations:', 'It', 'requires', 'specialized', 'software', '(it', 'may', 'be', 'challenging', 'and', 'time', 'consuming).', 'b)', 'The', 'Expectation-maximization', '(EM)', 'algorithm:', 'It', 'provides', 'estimates', 'of', 'the', 'means', 'and', 'covariance', 'matrix,', 'which', 'can', 'be', 'used', 'to', 'get', 'consistent', 'estimates', 'of', 'the', 'parameters', 'of', 'interest.', 'It', 'is', 'based', 'on', 'an', 'expectation', 'step', 'and', 'a', 'maximization', 'step,', 'which', 'are', 'repeated', 'several', 'times', 'until', 'maximum', 'likelihood', 'estimates', 'are', 'obtained.', 'It', 'requires', 'a', 'large', 'sample', 'size', 'and', 'that', 'the', 'data', 'are', 'missing', 'at', 'random', '(MAR).', 'Advantage:', 'We', 'can', 'use', 'SAS,', 'since', 'this', 'is', 'the', 'default', 'algorithm', 'it', 'employs', 'for', 'dealing', 'with', 'missing', 'data', 'with', 'Maximum', 'Likelihood.', 'Limitations:', 'Only', 'can', 'be', 'used', 'for', 'linear', 'and', 'log-linear', 'models', '(there', 'is', 'neither', 'theory', 'nor', 'software', 'developed', 'beyond', 'them).', '(Allison,', '2001)', '(Graham,', '2009)', '(Enders', '&', 'Bandalos,', '2001)', 'and', '(Allison,', '2003)', 'Sources', 'and', 'References:', '\\xe2\\x80\\xa2', 'http://handbook.cochrane.org/chapter_16/16_1_2_general_principles_for_dealing_with_missing_data.htm', '\\xe2\\x80\\xa2', 'https://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf', '\\xe2\\x80\\xa2', 'http://www.measuringu.com/blog/handle-missing-data.php', '\\xe2\\x80\\xa2', 'http://www.bu.edu/sph/files/2014/05/Marina-tech-report.pdf', '\\xe2\\x80\\xa2', 'http://galton.uchicago.edu/~eichler/stat24600/Admin/MissingDataReview.pdf']\n"
     ]
    }
   ],
   "source": [
    "Cat_2('C:/Users/hgsgautam/Desktop/Python/TestText.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Cat_3(filename):\n",
    "    f = open(filename, 'r')\n",
    "    text1 = f.read()\n",
    "    d1 = text1.split()\n",
    "    dic={}\n",
    "    for i in d1:\n",
    "            dic[i] = d1.count(i)\n",
    "    print(dic)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all': 4, '(it': 1, 'procedure.': 1, 'Advantages:': 2, 'results': 1, 'leads': 2, 'scale,': 2, 'decisions': 1, 'subjects': 1, '(in': 1, 'Mechanisms': 1, 'to': 44, 'methods:': 1, 'helps': 1, 'questions,': 1, 'risky': 1, 'very': 2, 'replaces': 1, 'every': 1, 'difference': 1, 'Bandalos,': 1, 'Expectation-maximization': 1, 'MAR': 3, 'specify': 1, 'solves': 1, 'presented': 1, 'did': 3, 'fewer': 1, 'Listwise': 1, 'item': 1, 'unrelated': 1, 'considering:': 1, 'Carlo': 1, 'clothes': 1, 'the': 81, 'software.': 1, 'imputation\".': 1, 'dealing': 1, 'consistent': 2, 'estimates': 9, 'direct': 1, 'likely': 5, 'estimated': 1, 'imputation\";': 1, 'depression': 2, 'theory': 1, 'what': 1, 'forms.': 1, 'There': 1, '\\xe2\\x80\\x9cbetween': 1, '\\xef\\x83\\x98': 8, 'experiment': 1, 'above': 1, 'error\\xe2\\x80\\x9d.': 1, 'method': 4, 'filled': 1, 'multivariate': 1, '(Schafer,': 2, 'error': 1, 'component': 1, '\"item': 1, 'here': 1, 'understanding': 1, 'reported': 1, 'groups': 1, '500.': 1, 'reality.': 1, 'obtained': 1, 'great': 1, 'parameters': 2, 'ML': 4, 'leaves': 1, 'MI': 2, 'reason': 1, 'commonly': 1, 'Markov': 1, 'trial': 1, 'survey': 2, '3.': 1, '3,': 1, '(Nakai': 1, 'involves': 1, 'Compared': 1, 'inference': 1, 'MAR,': 1, 'When': 2, 'E.x.:': 1, 'rarely': 1, 'select': 1, 'use': 10, 'average,': 1, 'from': 5, 'proceed': 1, 'would': 3, '&': 2, 'value.': 4, 'two': 2, 'properties': 1, 'predict': 1, 'sample': 6, 'Direct': 1, 'until': 1, 'more': 6, 'introducing': 1, '(MCAR),': 1, 'These': 1, 'operators': 1, 'http://www.bu.edu/sph/files/2014/05/Marina-tech-report.pdf': 1, 'MCAR': 3, 'basically': 1, '(SAS': 1, 'known': 2, 'cases': 2, 'must': 1, 'm=20': 1, 'and,': 2, 'middle': 1, 'this': 6, 'midpoint,': 1, 'equation': 1, 'work': 1, 'scenario.': 1, 'values': 12, 'can': 14, 'following': 1, 'specialized': 1, 'numbers': 1, 'compare': 1, 'weaker': 1, 'challenging': 2, 'give': 1, 'process': 2, 'household': 1, 'high': 1, 'unbiased': 1, 'caution': 1, 'something': 1, 'want': 2, 'exclude': 1, 'statistics,': 1, 'information': 2, 'needs': 1, 'Missing': 7, 'get': 5, 'steps:': 1, 'how': 2, 'Respondents': 2, 'reject': 1, 'optimal': 1, 'Essentially,': 1, 'parameter': 3, 'algorithm:': 1, 'A': 1, 'attend': 1, 'replacing': 1, 'Values:': 1, 'Imputation': 1, 'Sensitive': 1, 'lot': 1, 'data': 32, 'Y)': 1, 'different)': 1, 'sets': 2, 'consistent,': 1, 'One': 1, 'Sources': 1, 'so': 1, 'cases,': 1, 'guessing,': 1, \"dry-cleaners'\": 1, 'y.': 1, 'hand,': 2, 'generally,': 1, 'satisfied': 1, 'Multiple': 2, 'course': 1, 'statistical': 3, 'them).': 1, 'still': 2, 'its': 1, 'before': 1, 'group': 1, 'then,': 1, 'chosen': 2, 'Here': 1, 'better': 1, 'estimating': 1, '(MAR)': 1, 'SAS': 1, '2.': 3, 'main': 2, 'might': 1, 'hypothesis,': 1, 'it.': 2, 'quality-of-life': 1, 'them': 1, 'good': 4, 'Maximum': 3, 'Thus,': 1, 'they': 4, 'not': 10, 'However,': 1, 'nor': 2, 'MI,': 1, '(MCAR)': 1, 'Marginal': 1, 'system,': 1, 'drop': 1, 'possibilities': 1, 'each': 3, 'found': 1, 'Weiming,': 1, 'outliers,': 1, \"isn't\": 1, 'mean': 5, 'Conditional': 2, 'doing': 1, 'Specification': 1, 'related': 2, 'expect': 1, 'Which': 1, 'measure': 1, '(': 1, 'et': 1, 'beyond': 1, 'special': 1, 'out': 1, 'large': 3, 'matrix': 2, 'since': 1, 'available?': 1, 'imputation:': 2, 'thus,': 2, 'participants': 3, 'squares': 2, 'correct': 1, 'nonignorable': 1, 'linear': 2, 'Guessing:': 1, 'given': 1, 'standard': 2, 'completely': 1, 'ask': 1, 'estimate': 1, 'likelihood': 2, 'generate': 1, 'Delete': 1, '100,': 1, 'X,': 1, 'Chain': 1, 'missingness?': 1, 'could': 2, 'times': 2, 'cases).': 1, 'assumed': 1, 'regress': 1, '(remember,': 1, 'etc.).': 1, 'probability': 3, 'occupations': 1, 'imputation.': 1, 'variables': 4, 'imputation,': 1, 'one': 1, 'errors?)': 1, 'done': 1, 'MCAR,': 1, 'sounds': 1, 'quality': 1, 'interest.': 2, 'size': 2, 'power.': 1, 'differ': 1, 'X.': 1, 'service': 1, 'indicate': 1, 'Monotone': 1, 'structured': 1, 'least': 2, '(there': 2, 'their': 2, 'Completely': 1, 'assumption': 5, 'points,': 1, '\"unit': 1, 'enough,': 1, 'Data': 1, 'final': 2, 'enough.': 1, 'a': 35, '1997).': 2, 'mostly': 1, 'that': 12, 'maximization': 2, 'completed': 1, 'This': 3, 'part': 1, 'intuitively),': 1, 'variable.': 2, 'SAS,': 1, 'representing': 1, 'than': 5, 'coefficients': 1, 'kind': 2, 'require': 1, 'see': 1, 'imputation': 7, '1%': 1, 'interview,': 1, 'were': 1, 'outcome': 1, '640.': 1, '1.': 3, 'and': 30, '2001)': 3, 'mind': 1, '(NMAR)': 1, 'wear.': 1, 'substantial': 1, 'unlikely': 1, 'have': 5, 'median.': 1, 'need': 2, 'participants.': 1, 'null': 1, 'any': 3, 'data,': 1, 'data.': 2, 'data)': 1, 'x,': 1, 'efficient': 4, 'point,': 2, 'this),': 1, 'mechanism': 3, 'without': 2, 'generalized': 1, 'which': 9, 'model.': 1, 'Common-Point': 1, 'obtained.': 1, 'simulation-based': 1, 'sure': 1, 'multiple': 3, 'normal': 2, 'who': 5, 'age.': 1, 'age,': 1, 'The': 10, 'class': 1, 'discarding': 1, 'Institute,': 1, 'sometimes': 1, 'Some': 2, 'http://www.measuringu.com/blog/handle-missing-data.php': 1, 'five-point': 1, '1,000': 1, 'Limitations:': 5, '2003).': 1, 'rating': 1, 'Proceed': 1, 'Fully': 1, 'Likelihood.': 1, 'random': 5, 'Likelihood:': 2, 'substituting': 2, 'We': 4, 'based': 3, 'depended': 1, 'dividing': 1, 'true': 1, '(Enders': 1, 'produces': 1, 'proportion': 1, 'sets.': 2, 'should': 4, '(such': 1, 're-create': 1, 'only': 3, 'Secondly,': 1, 'developed': 1, '2005).': 1, 'achieve': 2, 'do': 1, 'handle': 2, 'means': 2, 'person\\xe2\\x80\\x99s': 1, 'expectation': 1, 'preferred': 1, 'Keep': 1, '99%': 1, 'cannot': 2, 'report': 5, 'X': 3, 'procedures': 1, 'determinants': 1, 'worst-case': 1, '(y)': 2, 'Random': 3, 'median': 1, 'variance-covariance': 1, 'default': 2, 'common': 1, 'contain': 1, 'x': 2, 'them,': 1, 'where': 1, 'Advantage:': 2, '(hopefully,': 1, 'set': 3, 'For': 5, 'violated': 1, 'testing': 1, '(Determine': 1, 'depends': 3, 'individual': 1, 'are': 19, 'fail': 1, 'close': 1, '(assuming': 1, 'subject': 1, 'said': 2, 'draws': 1, 'ways': 1, 'pattern': 2, 'nature': 1, 'sets,': 1, '3': 1, 'between': 2, 'helps.': 1, 'neither': 2, 'across': 1, '360': 1, 'available': 1, 'gives': 1, 'we': 10, '(MCMC)': 1, 'missing': 35, 'Jeffreys-,': 1, 'efficiency': 1, 'wear': 1, 'key': 1, 'Each': 1, 'analyzed': 1, '20': 1, 'substitute': 2, 'Monte': 1, 'Deletion:': 1, 'estimates.': 2, 'fulfilled': 1, 'estimation': 1, 'asked': 1, 'values.': 6, 'among': 1, 'limitations.': 1, 'efficient,': 1, 'errors.': 1, 'conclude': 1, 'simple': 1, 'asymptotically': 2, 'iterations': 1, \"it's\": 1, 'create': 1, 'least-squares': 1, 'responds': 1, 'were,': 1, 'performance).': 1, 'interest': 1, 'certain': 1, 'step,': 1, 'life': 1, 'options.': 1, 'covariance': 2, 'optimality': 1, 'those': 5, 'missings': 1, 'Estimating': 1, 'variances': 1, 'single': 1, 'value': 7, 'choices': 1, 'will': 1, '(Briggs': 1, 'suppose': 1, 'many': 4, 'income,': 1, 'income.': 2, 'studies,': 1, '(EM)': 1, 'then': 4, 'http://galton.uchicago.edu/~eichler/stat24600/Admin/MissingDataReview.pdf': 1, 'ones,': 1, 'is': 34, '2001).': 2, 'it': 8, '2009)': 2, 'in': 11, 'You': 1, 'regression': 2, 'if': 5, 'different': 4, 'participant': 3, 'prior': 1, 'same': 3, 'Correct': 1, 'question,': 1, 'several': 1, 'Example:': 3, 'infer': 1, 'independent': 2, 'used': 4, 'consuming).': 1, 'inadvertently': 1, 'Do': 1, 'https://liberalarts.utexas.edu/prc/_files/cs/Missing-Data.pdf': 1, 'References:': 1, 'common?)': 1, 'purpose': 1, 'Y': 1, 'relapse': 1, '(MAR).': 1, 'Thirdly,': 1, 'fully': 1, 'try': 1, 'modeled': 1, 'well': 1, 'It': 16, 'analysis': 1, 'values,': 1, 'patterns': 1, 'contact': 1, 'In': 3, 'y': 2, 'entry': 1, 'model': 9, 'researchers': 1, 'If': 7, 'Then,': 1, 'less': 4, 'being': 1, '-': 4, 'produce,': 1, 'identify': 1, 'ML,': 1, 'questions': 2, 'Be': 1, 'field': 1, \"we've\": 1, 'point': 1, 'had': 1, 'Running': 1, '(E.g.': 2, 'valid': 1, 'samples': 1, 'has': 3, 'On': 2, 'customers': 1, 'prefer': 1, 'process.': 1, 'possible': 1, 'required.': 1, 'action,': 1, 'know': 1, 'using': 6, 'bit': 2, 'postal': 1, 'like': 1, 'loss': 1, 'lost': 1, 'missing.': 2, 'systematically': 1, 'sample.': 1, '(MI)': 1, 'Are': 2, 'arbitrary': 1, '5%': 1, 'Firstly,': 1, 'works': 1, 'Imputation:': 2, 'matrix,': 2, 'because': 1, 'often': 2, 'people': 3, 'it,': 1, 'successfully': 1, 'some': 5, 'b)': 2, 'unless': 1, 'little': 1, '(Allison,': 5, 'happens': 1, 'Educated': 1, 'for': 12, '(whether': 1, 'models': 1, 'imputed': 3, 'provides': 1, 'limitations': 1, 'be': 17, 'biased': 1, 'example,': 3, 'Its': 1, 'conventional': 1, 'arbitrary?': 1, 'step': 1, 'substituted': 1, 'relationship': 1, 'variation': 1, 'dry-cleaner': 1, 'http://handbook.cochrane.org/chapter_16/16_1_2_general_principles_for_dealing_with_missing_data.htm': 1, 'by': 4, 'simpler': 1, 'on': 14, 'about': 1, 'Recover': 1, 'most': 2, 'of': 53, 'non-missing': 1, 'avoided.': 1, '\\xe2\\x80\\xa2': 5, 'ignorable,': 1, 'slightly': 1, 'or': 8, 'software': 2, 'Use': 1, 'computational': 1, 'into': 1, 'within': 1, 'dataset': 1, 'assess': 2, 'Few': 1, 'weighted': 1, '\"4s\",': 1, 'fulfilled:': 2, 'your': 7, 'methods': 2, 'additional': 2, 'removing': 1, 'support': 1, 'there': 4, 'age).': 1, 'variation.': 1, '2003)': 1, 'use-the': 1, 'fraction': 1, 'was': 1, '(i.e.': 1, 'combined': 1, 'function': 1, 'Compute': 1, 'complete': 4, 'form': 2, 'estimator,': 1, 'estimator.': 1, 'variance-': 1, 'removes': 1, 'but': 6, 'repeated': 1, 'Suppose': 1, 'log-linear': 1, 'with': 20, 'caution.': 1, \"I'll\": 2, 'compute': 1, 'whether': 1, 'maximum': 1, 'us': 1, 'considered': 1, 'below': 1, 'impute': 1, 'employs': 1, '2011),': 1, 'distribution': 2, 'are:': 1, 'called': 1, 'missingness': 1, 'defined': 1, 'm': 3, 'c)': 1, 'an': 5, 'as': 9, 'words,': 1, 'exist': 1, 'at': 7, 'follow-up': 1, 'our': 1, 'check': 1, 'fill': 3, 'al.,': 1, 'Only': 1, 'no': 2, '(FCS),': 1, 'when': 3, '4.': 1, 'individuals,': 1, '4,': 1, 'other': 5, 'income': 7, 'test': 1, 'you': 9, 'acceptable': 1, 'in-person': 1, '(Graham,': 2, 'distribution,': 1, 'may': 1, 'a)': 2, 'covariances': 1, 'inherently': 1, 'cover.': 1, 'variable': 1, 'younger': 1, 'implies': 1, 'lead': 2, 'algorithm': 1, 'tested': 2, 'assume': 1, 'variables?': 1, 'age': 1, 'variables.': 3, 'original': 2, 'increases)': 1, 'situations': 1, 'trial,': 1, 'time': 2, 'questionnaires': 1, 'understand': 1, 'requires': 4, 'having': 1}\n"
     ]
    }
   ],
   "source": [
    "Cat_3('C:/Users/hgsgautam/Desktop/Python/TestText.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = ['a', 'b', 'c', 'a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.count('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEBUG',\n",
       " 'DOTALL',\n",
       " 'I',\n",
       " 'IGNORECASE',\n",
       " 'L',\n",
       " 'LOCALE',\n",
       " 'M',\n",
       " 'MULTILINE',\n",
       " 'S',\n",
       " 'Scanner',\n",
       " 'T',\n",
       " 'TEMPLATE',\n",
       " 'U',\n",
       " 'UNICODE',\n",
       " 'VERBOSE',\n",
       " 'X',\n",
       " '_MAXCACHE',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__version__',\n",
       " '_alphanum',\n",
       " '_cache',\n",
       " '_cache_repl',\n",
       " '_compile',\n",
       " '_compile_repl',\n",
       " '_expand',\n",
       " '_locale',\n",
       " '_pattern_type',\n",
       " '_pickle',\n",
       " '_subx',\n",
       " 'compile',\n",
       " 'copy_reg',\n",
       " 'error',\n",
       " 'escape',\n",
       " 'findall',\n",
       " 'finditer',\n",
       " 'match',\n",
       " 'purge',\n",
       " 'search',\n",
       " 'split',\n",
       " 'sre_compile',\n",
       " 'sre_parse',\n",
       " 'sub',\n",
       " 'subn',\n",
       " 'sys',\n",
       " 'template']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F_OK',\n",
       " 'O_APPEND',\n",
       " 'O_BINARY',\n",
       " 'O_CREAT',\n",
       " 'O_EXCL',\n",
       " 'O_NOINHERIT',\n",
       " 'O_RANDOM',\n",
       " 'O_RDONLY',\n",
       " 'O_RDWR',\n",
       " 'O_SEQUENTIAL',\n",
       " 'O_SHORT_LIVED',\n",
       " 'O_TEMPORARY',\n",
       " 'O_TEXT',\n",
       " 'O_TRUNC',\n",
       " 'O_WRONLY',\n",
       " 'P_DETACH',\n",
       " 'P_NOWAIT',\n",
       " 'P_NOWAITO',\n",
       " 'P_OVERLAY',\n",
       " 'P_WAIT',\n",
       " 'R_OK',\n",
       " 'SEEK_CUR',\n",
       " 'SEEK_END',\n",
       " 'SEEK_SET',\n",
       " 'TMP_MAX',\n",
       " 'UserDict',\n",
       " 'W_OK',\n",
       " 'X_OK',\n",
       " '_Environ',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '_copy_reg',\n",
       " '_execvpe',\n",
       " '_exists',\n",
       " '_exit',\n",
       " '_get_exports_list',\n",
       " '_make_stat_result',\n",
       " '_make_statvfs_result',\n",
       " '_pickle_stat_result',\n",
       " '_pickle_statvfs_result',\n",
       " 'abort',\n",
       " 'access',\n",
       " 'altsep',\n",
       " 'chdir',\n",
       " 'chmod',\n",
       " 'close',\n",
       " 'closerange',\n",
       " 'curdir',\n",
       " 'defpath',\n",
       " 'devnull',\n",
       " 'dup',\n",
       " 'dup2',\n",
       " 'environ',\n",
       " 'errno',\n",
       " 'error',\n",
       " 'execl',\n",
       " 'execle',\n",
       " 'execlp',\n",
       " 'execlpe',\n",
       " 'execv',\n",
       " 'execve',\n",
       " 'execvp',\n",
       " 'execvpe',\n",
       " 'extsep',\n",
       " 'fdopen',\n",
       " 'fstat',\n",
       " 'fsync',\n",
       " 'getcwd',\n",
       " 'getcwdu',\n",
       " 'getenv',\n",
       " 'getpid',\n",
       " 'isatty',\n",
       " 'kill',\n",
       " 'linesep',\n",
       " 'listdir',\n",
       " 'lseek',\n",
       " 'lstat',\n",
       " 'makedirs',\n",
       " 'mkdir',\n",
       " 'name',\n",
       " 'open',\n",
       " 'pardir',\n",
       " 'path',\n",
       " 'pathsep',\n",
       " 'pipe',\n",
       " 'popen',\n",
       " 'popen2',\n",
       " 'popen3',\n",
       " 'popen4',\n",
       " 'putenv',\n",
       " 'read',\n",
       " 'remove',\n",
       " 'removedirs',\n",
       " 'rename',\n",
       " 'renames',\n",
       " 'rmdir',\n",
       " 'sep',\n",
       " 'spawnl',\n",
       " 'spawnle',\n",
       " 'spawnv',\n",
       " 'spawnve',\n",
       " 'startfile',\n",
       " 'stat',\n",
       " 'stat_float_times',\n",
       " 'stat_result',\n",
       " 'statvfs_result',\n",
       " 'strerror',\n",
       " 'sys',\n",
       " 'system',\n",
       " 'tempnam',\n",
       " 'times',\n",
       " 'tmpfile',\n",
       " 'tmpnam',\n",
       " 'umask',\n",
       " 'unlink',\n",
       " 'unsetenv',\n",
       " 'urandom',\n",
       " 'utime',\n",
       " 'waitpid',\n",
       " 'walk',\n",
       " 'write']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Error',\n",
       " 'ExecError',\n",
       " 'SpecialFileError',\n",
       " '_ARCHIVE_FORMATS',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '_basename',\n",
       " '_call_external_zip',\n",
       " '_destinsrc',\n",
       " '_get_gid',\n",
       " '_get_uid',\n",
       " '_make_tarball',\n",
       " '_make_zipfile',\n",
       " '_samefile',\n",
       " 'abspath',\n",
       " 'collections',\n",
       " 'copy',\n",
       " 'copy2',\n",
       " 'copyfile',\n",
       " 'copyfileobj',\n",
       " 'copymode',\n",
       " 'copystat',\n",
       " 'copytree',\n",
       " 'errno',\n",
       " 'fnmatch',\n",
       " 'get_archive_formats',\n",
       " 'getgrnam',\n",
       " 'getpwnam',\n",
       " 'ignore_patterns',\n",
       " 'make_archive',\n",
       " 'move',\n",
       " 'os',\n",
       " 'register_archive_format',\n",
       " 'rmtree',\n",
       " 'stat',\n",
       " 'sys',\n",
       " 'unregister_archive_format']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(shutil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "source": [
    " for line in b: print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li = ['a', 'b', 'new', 'mpilgrim', 'z', 'example', 'new', 'two', 'elements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li.extend('extend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'new',\n",
       " 'mpilgrim',\n",
       " 'z',\n",
       " 'example',\n",
       " 'new',\n",
       " 'two',\n",
       " 'elements',\n",
       " 'e',\n",
       " 'x',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 'd']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'new',\n",
       " 'mpilgrim',\n",
       " 'z',\n",
       " 'example',\n",
       " 'new',\n",
       " 'two',\n",
       " 'elements',\n",
       " 'extend']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li.append('extend')\n",
    "li\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li.append([\"extended\", \"evenfurther\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'new',\n",
       " 'mpilgrim',\n",
       " 'z',\n",
       " 'example',\n",
       " 'new',\n",
       " 'two',\n",
       " 'elements',\n",
       " 'extend',\n",
       " ['extended', 'evenfurther']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li.extend([\"extended\", \"evenfurther\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'new',\n",
       " 'mpilgrim',\n",
       " 'z',\n",
       " 'example',\n",
       " 'new',\n",
       " 'two',\n",
       " 'elements',\n",
       " 'extend',\n",
       " ['extended', 'evenfurther'],\n",
       " 'extended',\n",
       " 'evenfurther']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "li.extend('example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'new',\n",
       " 'mpilgrim',\n",
       " 'z',\n",
       " 'example',\n",
       " 'new',\n",
       " 'two',\n",
       " 'elements',\n",
       " 'extend',\n",
       " ['extended', 'evenfurther'],\n",
       " 'extended',\n",
       " 'evenfurther',\n",
       " 'extended',\n",
       " 'evenfurther',\n",
       " 'e',\n",
       " 'x',\n",
       " 'a',\n",
       " 'm',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfp = ['user_id', 'gender', 'age', 'occupation', 'zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'gender', 'age', 'occupation', 'zip']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dfp = pd.DataFrame({\n",
    "        'user_id': np.array([1,2,3,4,5],dtype='int32'),\n",
    "        'gender': pd.Categorical ([\"Male\",\"Female\",\"Male\",\"Female\",\"Female\"]),\n",
    "        'age': np.array([22,23,26,28,61],dtype='int32'),\n",
    "        'occupation': pd.Categorical ([\"10\", \"16\",\"5\", \"16\", \"8\"]),\n",
    "        'zip': pd.Categorical ([\"48067\", \"55864\", \"54564\", \"54515\", \"15155\"])    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>55864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>54564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>54515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>Female</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>15155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender occupation  user_id    zip\n",
       "0   22    Male         10        1  48067\n",
       "1   23  Female         16        2  55864\n",
       "2   26    Male          5        3  54564\n",
       "3   28  Female         16        4  54515\n",
       "4   61  Female          8        5  15155"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender_new = []\n",
    "\n",
    "for i in dfp.gender:\n",
    "        gender_new.append(i[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'F', 'M', 'F', 'F']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfp.gender = gender_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>user_id</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>55864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>54564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>54515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>15155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age gender occupation  user_id    zip\n",
       "0   22      M         10        1  48067\n",
       "1   23      F         16        2  55864\n",
       "2   26      M          5        3  54564\n",
       "3   28      F         16        4  54515\n",
       "4   61      F          8        5  15155"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gender_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftest = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender\n",
       "0      M\n",
       "1      F\n",
       "2      M\n",
       "3      F\n",
       "4      F"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = []\n",
    "for i in dfp.gender:\n",
    "    ser.append(i)\n",
    "    \n",
    "dftest['Gender'] = ser\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = dftest.drop('Gender', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
